{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of IMBD Movie Ratings with RNN \n",
    "\n",
    "The notebook includes text preprocessing along with the embedding part and the training using customly written LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../IMDB-Dataset.csv\" # path to a csv file downloaded form https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing and Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our dataset that is currently in a CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading csv data\n",
    "data_path = root\n",
    "df = pd.read_csv(data_path)\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x:1 if x == 'positive' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use in RNN tasks we need to tokenize our dataset and bring it into compatible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [s.lower() for s in re.split(r'\\W+', text) if s]\n",
    "\n",
    "\n",
    "# Maximum tokens allowed per review.\n",
    "max_tokens = 80\n",
    "\n",
    "# Defining set of stopwords to remove from the vocabulary and token lists.\n",
    "stop_words = {\"a\", \"an\", \"and\", \"the\"}\n",
    "\n",
    "\n",
    "# Building the vocabulary using training data.\n",
    "freqs = Counter()\n",
    "for text in train_df['review']:\n",
    "    tokens = [token for token in tokenize(text) if token not in stop_words][:max_tokens]\n",
    "    freqs.update(tokens)\n",
    "\n",
    "# Initializing the vocabulary with special tokens.\n",
    "vocab = {'<eos>': 0, '<unk>': 1}\n",
    "# Adding the 50 most common tokens from the training data.\n",
    "for token, _ in freqs.most_common(50):\n",
    "    vocab[token] = len(vocab)\n",
    "\n",
    "\n",
    "# Mapping Tokens to unique indices\n",
    "# if token does not exist in vocabulary we assign it to <unk> token\n",
    "def tokens_to_indices(tokens, vocab):\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "\n",
    "# Preparing data: Creating tuples (raw_text, tokens, token_indices, sentiment).\n",
    "def prepare_data(df, vocab, max_tokens=40):\n",
    "    data_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        raw_text = row['review']\n",
    "        sentiment = row['sentiment']\n",
    "        tokens = tokenize(raw_text)[:max_tokens]  # truncating tokens\n",
    "        indices = tokens_to_indices(tokens, vocab)\n",
    "        data_list.append((raw_text, tokens, indices, sentiment))\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'of': 86474,\n",
       "         'to': 74070,\n",
       "         'i': 69669,\n",
       "         'is': 64651,\n",
       "         'it': 61590,\n",
       "         'this': 54924,\n",
       "         'in': 53014,\n",
       "         'br': 48456,\n",
       "         'that': 40760,\n",
       "         'was': 35086,\n",
       "         'movie': 33781,\n",
       "         's': 33139,\n",
       "         'film': 25914,\n",
       "         'as': 24935,\n",
       "         'with': 24597,\n",
       "         'for': 23975,\n",
       "         'but': 23867,\n",
       "         'on': 20404,\n",
       "         't': 19048,\n",
       "         'you': 18101,\n",
       "         'not': 17667,\n",
       "         'have': 17258,\n",
       "         'one': 17105,\n",
       "         'are': 16079,\n",
       "         'be': 14942,\n",
       "         'his': 14144,\n",
       "         'at': 13339,\n",
       "         'all': 13186,\n",
       "         'he': 13020,\n",
       "         'by': 12878,\n",
       "         'so': 12551,\n",
       "         'who': 12301,\n",
       "         'from': 12063,\n",
       "         'like': 11762,\n",
       "         'they': 11576,\n",
       "         'about': 11419,\n",
       "         'has': 10365,\n",
       "         'there': 10328,\n",
       "         'just': 10079,\n",
       "         'what': 9677,\n",
       "         'my': 9453,\n",
       "         'good': 9350,\n",
       "         'or': 9174,\n",
       "         'very': 9129,\n",
       "         'out': 9090,\n",
       "         'some': 9041,\n",
       "         'if': 8614,\n",
       "         'when': 8604,\n",
       "         'story': 8320,\n",
       "         'can': 8226,\n",
       "         'time': 7586,\n",
       "         'her': 7538,\n",
       "         'had': 7411,\n",
       "         'really': 7265,\n",
       "         'me': 7140,\n",
       "         'no': 7100,\n",
       "         'first': 7038,\n",
       "         'up': 7008,\n",
       "         'more': 7005,\n",
       "         'even': 6676,\n",
       "         'only': 6648,\n",
       "         'would': 6640,\n",
       "         'were': 6632,\n",
       "         'bad': 6625,\n",
       "         'see': 6534,\n",
       "         'great': 6400,\n",
       "         'well': 6354,\n",
       "         'movies': 6239,\n",
       "         'which': 6214,\n",
       "         'she': 5818,\n",
       "         'their': 5772,\n",
       "         'people': 5600,\n",
       "         'been': 5597,\n",
       "         'made': 5597,\n",
       "         'seen': 5525,\n",
       "         'most': 5514,\n",
       "         'much': 5490,\n",
       "         'how': 5284,\n",
       "         'because': 5266,\n",
       "         'we': 5241,\n",
       "         'than': 5161,\n",
       "         'plot': 5043,\n",
       "         'don': 4924,\n",
       "         'other': 4903,\n",
       "         'its': 4896,\n",
       "         'get': 4894,\n",
       "         'acting': 4864,\n",
       "         'into': 4856,\n",
       "         'ever': 4830,\n",
       "         'films': 4824,\n",
       "         'after': 4771,\n",
       "         'do': 4626,\n",
       "         'could': 4401,\n",
       "         'will': 4399,\n",
       "         'best': 4383,\n",
       "         'many': 4354,\n",
       "         'think': 4348,\n",
       "         'make': 4316,\n",
       "         'characters': 4309,\n",
       "         'way': 4235,\n",
       "         'love': 4231,\n",
       "         'watch': 4204,\n",
       "         'then': 4126,\n",
       "         'also': 4125,\n",
       "         'show': 4091,\n",
       "         'two': 4061,\n",
       "         'too': 3941,\n",
       "         'any': 3915,\n",
       "         'life': 3889,\n",
       "         'know': 3841,\n",
       "         'them': 3783,\n",
       "         'never': 3774,\n",
       "         've': 3752,\n",
       "         'did': 3714,\n",
       "         'little': 3630,\n",
       "         'being': 3629,\n",
       "         'say': 3534,\n",
       "         'over': 3509,\n",
       "         'character': 3470,\n",
       "         'where': 3445,\n",
       "         'man': 3432,\n",
       "         'watching': 3373,\n",
       "         'him': 3329,\n",
       "         'off': 3317,\n",
       "         'years': 3294,\n",
       "         'saw': 3277,\n",
       "         'm': 3276,\n",
       "         'better': 3127,\n",
       "         'funny': 3095,\n",
       "         'actors': 3014,\n",
       "         'still': 2974,\n",
       "         'why': 2933,\n",
       "         'here': 2932,\n",
       "         'such': 2871,\n",
       "         'while': 2855,\n",
       "         'does': 2845,\n",
       "         'through': 2817,\n",
       "         'old': 2798,\n",
       "         'didn': 2757,\n",
       "         'director': 2753,\n",
       "         'thought': 2750,\n",
       "         'now': 2744,\n",
       "         'something': 2735,\n",
       "         'those': 2732,\n",
       "         'back': 2711,\n",
       "         'your': 2709,\n",
       "         'new': 2679,\n",
       "         'scenes': 2634,\n",
       "         'should': 2626,\n",
       "         'horror': 2622,\n",
       "         'these': 2620,\n",
       "         'thing': 2594,\n",
       "         'lot': 2555,\n",
       "         'end': 2554,\n",
       "         'go': 2541,\n",
       "         'every': 2535,\n",
       "         'real': 2508,\n",
       "         'few': 2489,\n",
       "         'actually': 2483,\n",
       "         'nothing': 2442,\n",
       "         'before': 2440,\n",
       "         'worst': 2433,\n",
       "         'cast': 2427,\n",
       "         'series': 2423,\n",
       "         'got': 2419,\n",
       "         'young': 2404,\n",
       "         'comedy': 2395,\n",
       "         'going': 2389,\n",
       "         'find': 2368,\n",
       "         'am': 2355,\n",
       "         'work': 2321,\n",
       "         'watched': 2306,\n",
       "         'though': 2288,\n",
       "         'same': 2285,\n",
       "         'world': 2280,\n",
       "         'big': 2279,\n",
       "         'scene': 2246,\n",
       "         'pretty': 2243,\n",
       "         'another': 2243,\n",
       "         'however': 2198,\n",
       "         'quite': 2191,\n",
       "         'original': 2188,\n",
       "         'look': 2180,\n",
       "         'makes': 2178,\n",
       "         'part': 2172,\n",
       "         'doesn': 2164,\n",
       "         'tv': 2157,\n",
       "         're': 2121,\n",
       "         'action': 2074,\n",
       "         'long': 2067,\n",
       "         'again': 2063,\n",
       "         'interesting': 2045,\n",
       "         'must': 2031,\n",
       "         'around': 2024,\n",
       "         'things': 2011,\n",
       "         'times': 1990,\n",
       "         'script': 1986,\n",
       "         'down': 1979,\n",
       "         'always': 1962,\n",
       "         'fact': 1933,\n",
       "         'since': 1928,\n",
       "         'music': 1918,\n",
       "         'us': 1907,\n",
       "         'found': 1905,\n",
       "         'family': 1905,\n",
       "         'take': 1858,\n",
       "         'both': 1855,\n",
       "         'seems': 1836,\n",
       "         'last': 1833,\n",
       "         'almost': 1824,\n",
       "         'want': 1799,\n",
       "         'right': 1798,\n",
       "         'minutes': 1794,\n",
       "         '2': 1788,\n",
       "         'may': 1764,\n",
       "         'without': 1759,\n",
       "         'far': 1756,\n",
       "         'between': 1734,\n",
       "         'enough': 1732,\n",
       "         'guy': 1721,\n",
       "         'come': 1716,\n",
       "         'done': 1708,\n",
       "         'hard': 1708,\n",
       "         'whole': 1707,\n",
       "         'fan': 1685,\n",
       "         'although': 1684,\n",
       "         'isn': 1669,\n",
       "         'anything': 1652,\n",
       "         'dvd': 1651,\n",
       "         'girl': 1644,\n",
       "         'year': 1643,\n",
       "         'give': 1637,\n",
       "         'probably': 1636,\n",
       "         'believe': 1631,\n",
       "         'gets': 1626,\n",
       "         'book': 1607,\n",
       "         'kind': 1607,\n",
       "         'd': 1602,\n",
       "         'night': 1595,\n",
       "         'least': 1591,\n",
       "         'fun': 1589,\n",
       "         '10': 1588,\n",
       "         'making': 1577,\n",
       "         'bit': 1575,\n",
       "         'feel': 1573,\n",
       "         'role': 1572,\n",
       "         'day': 1571,\n",
       "         'having': 1568,\n",
       "         'american': 1564,\n",
       "         'high': 1550,\n",
       "         'excellent': 1543,\n",
       "         'woman': 1539,\n",
       "         'own': 1537,\n",
       "         'set': 1531,\n",
       "         'especially': 1509,\n",
       "         'anyone': 1507,\n",
       "         'yet': 1507,\n",
       "         'wasn': 1506,\n",
       "         'everything': 1500,\n",
       "         'sure': 1499,\n",
       "         'performance': 1498,\n",
       "         'played': 1488,\n",
       "         'read': 1480,\n",
       "         'seeing': 1474,\n",
       "         'looking': 1472,\n",
       "         'effects': 1471,\n",
       "         'shows': 1469,\n",
       "         'war': 1468,\n",
       "         'three': 1443,\n",
       "         'each': 1438,\n",
       "         'special': 1438,\n",
       "         'main': 1438,\n",
       "         'different': 1436,\n",
       "         'might': 1428,\n",
       "         'point': 1423,\n",
       "         'awful': 1416,\n",
       "         'john': 1409,\n",
       "         'plays': 1407,\n",
       "         'budget': 1393,\n",
       "         'actor': 1389,\n",
       "         'let': 1388,\n",
       "         'away': 1379,\n",
       "         'star': 1365,\n",
       "         'trying': 1365,\n",
       "         'low': 1361,\n",
       "         'true': 1356,\n",
       "         'play': 1355,\n",
       "         'put': 1343,\n",
       "         'screen': 1342,\n",
       "         'terrible': 1336,\n",
       "         'll': 1336,\n",
       "         'idea': 1335,\n",
       "         'beautiful': 1333,\n",
       "         'rather': 1332,\n",
       "         'reason': 1323,\n",
       "         '1': 1318,\n",
       "         'version': 1315,\n",
       "         'together': 1307,\n",
       "         'classic': 1304,\n",
       "         'once': 1303,\n",
       "         'loved': 1301,\n",
       "         'video': 1300,\n",
       "         'goes': 1299,\n",
       "         'boring': 1282,\n",
       "         'came': 1281,\n",
       "         'short': 1278,\n",
       "         'remember': 1276,\n",
       "         'everyone': 1275,\n",
       "         'during': 1273,\n",
       "         'school': 1267,\n",
       "         'takes': 1263,\n",
       "         'friends': 1253,\n",
       "         'based': 1252,\n",
       "         'black': 1244,\n",
       "         'someone': 1241,\n",
       "         'half': 1239,\n",
       "         'said': 1236,\n",
       "         'our': 1233,\n",
       "         'job': 1229,\n",
       "         'course': 1226,\n",
       "         'start': 1225,\n",
       "         'comes': 1213,\n",
       "         'place': 1207,\n",
       "         'hollywood': 1203,\n",
       "         'production': 1197,\n",
       "         'wonderful': 1192,\n",
       "         'maybe': 1191,\n",
       "         'poor': 1189,\n",
       "         'money': 1189,\n",
       "         'wrong': 1183,\n",
       "         'looks': 1178,\n",
       "         'second': 1176,\n",
       "         'house': 1168,\n",
       "         'wife': 1162,\n",
       "         'sense': 1149,\n",
       "         'line': 1142,\n",
       "         'stupid': 1141,\n",
       "         'absolutely': 1141,\n",
       "         'written': 1133,\n",
       "         'kids': 1126,\n",
       "         'went': 1116,\n",
       "         'top': 1115,\n",
       "         '3': 1110,\n",
       "         'episode': 1102,\n",
       "         'seem': 1098,\n",
       "         'early': 1094,\n",
       "         'liked': 1089,\n",
       "         'completely': 1086,\n",
       "         'along': 1085,\n",
       "         'shot': 1084,\n",
       "         'title': 1083,\n",
       "         'worth': 1079,\n",
       "         'performances': 1076,\n",
       "         'full': 1075,\n",
       "         'mind': 1073,\n",
       "         'used': 1071,\n",
       "         'left': 1069,\n",
       "         'home': 1064,\n",
       "         'enjoyed': 1055,\n",
       "         'couple': 1050,\n",
       "         'name': 1043,\n",
       "         'later': 1042,\n",
       "         'until': 1042,\n",
       "         'audience': 1036,\n",
       "         'truly': 1033,\n",
       "         'nice': 1030,\n",
       "         'couldn': 1029,\n",
       "         'simply': 1027,\n",
       "         'women': 1027,\n",
       "         'understand': 1025,\n",
       "         'drama': 1024,\n",
       "         'entertaining': 1021,\n",
       "         'stars': 1020,\n",
       "         'instead': 1020,\n",
       "         'worse': 1020,\n",
       "         'death': 1020,\n",
       "         'father': 1014,\n",
       "         'piece': 1014,\n",
       "         'enjoy': 1014,\n",
       "         'boy': 1007,\n",
       "         'men': 1004,\n",
       "         'mean': 999,\n",
       "         'called': 993,\n",
       "         'beginning': 990,\n",
       "         'dead': 989,\n",
       "         'ending': 988,\n",
       "         'else': 978,\n",
       "         'horrible': 970,\n",
       "         'directed': 969,\n",
       "         'less': 968,\n",
       "         'small': 968,\n",
       "         'yes': 965,\n",
       "         'cinema': 963,\n",
       "         'favorite': 963,\n",
       "         'perfect': 961,\n",
       "         'several': 960,\n",
       "         'tell': 957,\n",
       "         'flick': 956,\n",
       "         'ago': 955,\n",
       "         'sex': 953,\n",
       "         'either': 953,\n",
       "         'children': 946,\n",
       "         'try': 944,\n",
       "         'friend': 941,\n",
       "         'given': 931,\n",
       "         'dialogue': 931,\n",
       "         'wanted': 922,\n",
       "         'style': 919,\n",
       "         'felt': 915,\n",
       "         'often': 915,\n",
       "         'himself': 910,\n",
       "         'others': 907,\n",
       "         'heard': 907,\n",
       "         'live': 901,\n",
       "         'seemed': 899,\n",
       "         'laugh': 895,\n",
       "         'mother': 894,\n",
       "         'humor': 891,\n",
       "         'amazing': 891,\n",
       "         'unfortunately': 888,\n",
       "         'itself': 885,\n",
       "         'definitely': 883,\n",
       "         'case': 881,\n",
       "         'totally': 880,\n",
       "         'late': 875,\n",
       "         'getting': 874,\n",
       "         'starts': 873,\n",
       "         'b': 872,\n",
       "         'need': 869,\n",
       "         'next': 867,\n",
       "         'person': 864,\n",
       "         'lives': 861,\n",
       "         'camera': 859,\n",
       "         'writing': 858,\n",
       "         'lead': 856,\n",
       "         'playing': 854,\n",
       "         'lost': 850,\n",
       "         'lines': 849,\n",
       "         'genre': 849,\n",
       "         'moments': 847,\n",
       "         'help': 846,\n",
       "         'quality': 844,\n",
       "         'days': 844,\n",
       "         'myself': 836,\n",
       "         'brilliant': 836,\n",
       "         'use': 836,\n",
       "         'ok': 834,\n",
       "         'certainly': 834,\n",
       "         'supposed': 833,\n",
       "         'direction': 833,\n",
       "         'picture': 833,\n",
       "         'problem': 832,\n",
       "         'history': 826,\n",
       "         'human': 826,\n",
       "         'oh': 824,\n",
       "         'perhaps': 823,\n",
       "         'game': 822,\n",
       "         'group': 822,\n",
       "         'expect': 821,\n",
       "         '5': 817,\n",
       "         'gave': 812,\n",
       "         'gives': 809,\n",
       "         'kid': 807,\n",
       "         'town': 804,\n",
       "         'dark': 803,\n",
       "         'won': 802,\n",
       "         'michael': 802,\n",
       "         'rest': 800,\n",
       "         'entire': 798,\n",
       "         'keep': 797,\n",
       "         'mr': 796,\n",
       "         'released': 795,\n",
       "         'documentary': 790,\n",
       "         'doing': 787,\n",
       "         'white': 782,\n",
       "         'etc': 773,\n",
       "         'started': 770,\n",
       "         'become': 769,\n",
       "         'known': 767,\n",
       "         'waste': 762,\n",
       "         'parts': 761,\n",
       "         'writer': 761,\n",
       "         'sound': 760,\n",
       "         'head': 760,\n",
       "         'art': 758,\n",
       "         'under': 756,\n",
       "         'already': 756,\n",
       "         'past': 752,\n",
       "         'run': 750,\n",
       "         'guys': 750,\n",
       "         'sort': 744,\n",
       "         'example': 744,\n",
       "         'thinking': 743,\n",
       "         'son': 743,\n",
       "         'killer': 743,\n",
       "         'city': 742,\n",
       "         'finally': 741,\n",
       "         'thriller': 741,\n",
       "         'stories': 736,\n",
       "         'child': 735,\n",
       "         'today': 734,\n",
       "         'took': 727,\n",
       "         'extremely': 726,\n",
       "         'disappointed': 726,\n",
       "         'reviews': 722,\n",
       "         'guess': 719,\n",
       "         'james': 718,\n",
       "         'actress': 716,\n",
       "         'evil': 715,\n",
       "         'usually': 712,\n",
       "         'review': 712,\n",
       "         'slow': 711,\n",
       "         'looked': 709,\n",
       "         'novel': 707,\n",
       "         'fine': 707,\n",
       "         'hour': 704,\n",
       "         'despite': 704,\n",
       "         'wants': 700,\n",
       "         'crap': 699,\n",
       "         'turn': 696,\n",
       "         'age': 694,\n",
       "         'tries': 693,\n",
       "         'face': 690,\n",
       "         'huge': 690,\n",
       "         'sometimes': 689,\n",
       "         'comments': 689,\n",
       "         'television': 689,\n",
       "         'hilarious': 688,\n",
       "         'heart': 688,\n",
       "         'robert': 684,\n",
       "         'throughout': 683,\n",
       "         'fans': 682,\n",
       "         'close': 682,\n",
       "         'type': 678,\n",
       "         'simple': 676,\n",
       "         'god': 676,\n",
       "         '4': 676,\n",
       "         'obviously': 674,\n",
       "         'girls': 673,\n",
       "         'works': 671,\n",
       "         'jokes': 669,\n",
       "         'daughter': 668,\n",
       "         'opening': 667,\n",
       "         'knew': 667,\n",
       "         'david': 667,\n",
       "         'told': 665,\n",
       "         'decent': 664,\n",
       "         'care': 659,\n",
       "         'against': 657,\n",
       "         'stop': 656,\n",
       "         'living': 653,\n",
       "         'basically': 649,\n",
       "         'attempt': 648,\n",
       "         'side': 648,\n",
       "         'turned': 647,\n",
       "         'murder': 644,\n",
       "         'able': 644,\n",
       "         'surprised': 643,\n",
       "         'storyline': 639,\n",
       "         'scary': 638,\n",
       "         'episodes': 637,\n",
       "         'premise': 637,\n",
       "         'cool': 636,\n",
       "         'across': 635,\n",
       "         'matter': 632,\n",
       "         'hit': 631,\n",
       "         'coming': 631,\n",
       "         'except': 630,\n",
       "         'viewer': 630,\n",
       "         'complete': 629,\n",
       "         'predictable': 627,\n",
       "         'behind': 626,\n",
       "         'recommend': 625,\n",
       "         'hope': 624,\n",
       "         'becomes': 623,\n",
       "         'involved': 622,\n",
       "         'act': 622,\n",
       "         'cannot': 622,\n",
       "         'spoilers': 619,\n",
       "         'eyes': 615,\n",
       "         'self': 615,\n",
       "         'tale': 615,\n",
       "         'word': 614,\n",
       "         'english': 612,\n",
       "         'british': 611,\n",
       "         'soon': 611,\n",
       "         'strange': 611,\n",
       "         'ridiculous': 608,\n",
       "         'four': 608,\n",
       "         'stuff': 608,\n",
       "         'class': 607,\n",
       "         'saying': 606,\n",
       "         'turns': 605,\n",
       "         'hell': 605,\n",
       "         'husband': 604,\n",
       "         'happened': 600,\n",
       "         'seriously': 600,\n",
       "         'serious': 600,\n",
       "         'decided': 599,\n",
       "         'experience': 598,\n",
       "         'hours': 598,\n",
       "         'talent': 597,\n",
       "         'brother': 597,\n",
       "         'usual': 594,\n",
       "         'car': 593,\n",
       "         'local': 593,\n",
       "         'sequel': 591,\n",
       "         'french': 591,\n",
       "         'middle': 590,\n",
       "         'strong': 587,\n",
       "         'upon': 582,\n",
       "         'beyond': 580,\n",
       "         'possible': 580,\n",
       "         'opinion': 579,\n",
       "         'themselves': 578,\n",
       "         'including': 577,\n",
       "         'happen': 575,\n",
       "         'country': 575,\n",
       "         'filmed': 574,\n",
       "         'greatest': 571,\n",
       "         'earth': 570,\n",
       "         'dialog': 570,\n",
       "         'imdb': 569,\n",
       "         'happens': 568,\n",
       "         'theater': 568,\n",
       "         'acted': 567,\n",
       "         'voice': 567,\n",
       "         'exactly': 566,\n",
       "         'chance': 566,\n",
       "         'tried': 566,\n",
       "         'sad': 564,\n",
       "         'mostly': 564,\n",
       "         'killed': 563,\n",
       "         'feeling': 561,\n",
       "         'hero': 560,\n",
       "         'recently': 560,\n",
       "         'modern': 560,\n",
       "         'shown': 560,\n",
       "         'highly': 559,\n",
       "         'silly': 557,\n",
       "         'kill': 557,\n",
       "         'musical': 557,\n",
       "         'single': 555,\n",
       "         'non': 555,\n",
       "         'romantic': 555,\n",
       "         'anyway': 555,\n",
       "         'cinematography': 553,\n",
       "         'taken': 552,\n",
       "         'jack': 552,\n",
       "         'none': 552,\n",
       "         'number': 549,\n",
       "         'typical': 548,\n",
       "         'expecting': 548,\n",
       "         'five': 548,\n",
       "         'wonder': 548,\n",
       "         'expected': 547,\n",
       "         'hand': 544,\n",
       "         'king': 544,\n",
       "         'obvious': 543,\n",
       "         'lots': 542,\n",
       "         'richard': 542,\n",
       "         'attention': 541,\n",
       "         'comment': 540,\n",
       "         'call': 540,\n",
       "         'blood': 538,\n",
       "         'somewhat': 538,\n",
       "         'major': 538,\n",
       "         'view': 538,\n",
       "         'haven': 537,\n",
       "         'roles': 536,\n",
       "         'george': 536,\n",
       "         'interest': 535,\n",
       "         'fi': 535,\n",
       "         'space': 533,\n",
       "         'particularly': 533,\n",
       "         'enjoyable': 533,\n",
       "         'lack': 533,\n",
       "         'gore': 531,\n",
       "         'sci': 531,\n",
       "         'fight': 530,\n",
       "         'bunch': 528,\n",
       "         'release': 528,\n",
       "         'ones': 527,\n",
       "         'police': 527,\n",
       "         'wish': 524,\n",
       "         'says': 524,\n",
       "         'order': 523,\n",
       "         'reality': 520,\n",
       "         'fast': 520,\n",
       "         'words': 520,\n",
       "         'cheap': 519,\n",
       "         'violence': 519,\n",
       "         'dull': 519,\n",
       "         'whose': 517,\n",
       "         'superb': 516,\n",
       "         'career': 515,\n",
       "         'moving': 514,\n",
       "         'problems': 513,\n",
       "         'ten': 513,\n",
       "         'feature': 512,\n",
       "         'okay': 512,\n",
       "         'annoying': 512,\n",
       "         'disney': 511,\n",
       "         'alone': 509,\n",
       "         'light': 509,\n",
       "         'o': 508,\n",
       "         'named': 507,\n",
       "         'suspense': 506,\n",
       "         'song': 504,\n",
       "         'team': 504,\n",
       "         'final': 503,\n",
       "         'hate': 502,\n",
       "         'york': 502,\n",
       "         'taking': 501,\n",
       "         'subject': 500,\n",
       "         'famous': 500,\n",
       "         'wouldn': 498,\n",
       "         'fantastic': 498,\n",
       "         'reading': 498,\n",
       "         'songs': 496,\n",
       "         'female': 496,\n",
       "         'leave': 496,\n",
       "         'rock': 494,\n",
       "         'rating': 494,\n",
       "         'running': 493,\n",
       "         'overall': 493,\n",
       "         'admit': 492,\n",
       "         'falls': 492,\n",
       "         'animation': 492,\n",
       "         '20': 491,\n",
       "         'peter': 491,\n",
       "         'talking': 491,\n",
       "         'straight': 488,\n",
       "         'important': 488,\n",
       "         'realistic': 487,\n",
       "         'crime': 486,\n",
       "         'due': 486,\n",
       "         'sister': 485,\n",
       "         '80': 483,\n",
       "         'power': 483,\n",
       "         'please': 480,\n",
       "         'lame': 480,\n",
       "         'tom': 479,\n",
       "         'cheesy': 479,\n",
       "         'poorly': 478,\n",
       "         'relationship': 477,\n",
       "         'happy': 475,\n",
       "         'brought': 474,\n",
       "         'tells': 474,\n",
       "         'entertainment': 473,\n",
       "         'parents': 472,\n",
       "         'doubt': 472,\n",
       "         'imagine': 471,\n",
       "         'period': 471,\n",
       "         'talk': 471,\n",
       "         'save': 471,\n",
       "         'level': 471,\n",
       "         'average': 471,\n",
       "         'cut': 469,\n",
       "         'easy': 469,\n",
       "         'apparently': 468,\n",
       "         'weak': 467,\n",
       "         'season': 467,\n",
       "         'change': 466,\n",
       "         'viewing': 466,\n",
       "         'similar': 464,\n",
       "         'body': 462,\n",
       "         'sets': 462,\n",
       "         'masterpiece': 461,\n",
       "         'gone': 459,\n",
       "         'add': 458,\n",
       "         'among': 457,\n",
       "         'easily': 455,\n",
       "         'soundtrack': 455,\n",
       "         'theme': 454,\n",
       "         'begin': 453,\n",
       "         'follow': 453,\n",
       "         'events': 453,\n",
       "         'box': 452,\n",
       "         'produced': 452,\n",
       "         'ways': 451,\n",
       "         'directing': 451,\n",
       "         'mystery': 451,\n",
       "         'kept': 450,\n",
       "         'surprise': 450,\n",
       "         'western': 450,\n",
       "         'remake': 450,\n",
       "         'boys': 450,\n",
       "         'write': 450,\n",
       "         'monster': 450,\n",
       "         'elements': 449,\n",
       "         'caught': 449,\n",
       "         'forward': 449,\n",
       "         'dr': 448,\n",
       "         'stand': 447,\n",
       "         'romance': 446,\n",
       "         'working': 444,\n",
       "         'agree': 444,\n",
       "         'above': 443,\n",
       "         'sit': 443,\n",
       "         'effort': 442,\n",
       "         'badly': 441,\n",
       "         'aren': 438,\n",
       "         'oscar': 438,\n",
       "         'finds': 437,\n",
       "         'meets': 436,\n",
       "         'miss': 436,\n",
       "         'copy': 435,\n",
       "         'island': 434,\n",
       "         'sorry': 434,\n",
       "         'comic': 433,\n",
       "         'lee': 432,\n",
       "         'editing': 432,\n",
       "         'score': 431,\n",
       "         'within': 430,\n",
       "         'lady': 429,\n",
       "         'moment': 429,\n",
       "         'bought': 429,\n",
       "         'deep': 428,\n",
       "         'cartoon': 427,\n",
       "         'certain': 427,\n",
       "         'nearly': 427,\n",
       "         'america': 426,\n",
       "         'rent': 425,\n",
       "         'cover': 425,\n",
       "         'fall': 424,\n",
       "         'college': 424,\n",
       "         'rented': 423,\n",
       "         'incredibly': 423,\n",
       "         'possibly': 423,\n",
       "         'century': 423,\n",
       "         'gay': 420,\n",
       "         'channel': 419,\n",
       "         'difficult': 419,\n",
       "         'festival': 419,\n",
       "         'near': 419,\n",
       "         'minute': 418,\n",
       "         'paul': 418,\n",
       "         'knows': 417,\n",
       "         'starring': 416,\n",
       "         'screenplay': 415,\n",
       "         'eye': 415,\n",
       "         '30': 414,\n",
       "         'became': 413,\n",
       "         'clearly': 413,\n",
       "         'shots': 412,\n",
       "         'wrote': 411,\n",
       "         'bring': 410,\n",
       "         'list': 410,\n",
       "         'believable': 409,\n",
       "         'future': 408,\n",
       "         'begins': 408,\n",
       "         'wow': 408,\n",
       "         'message': 407,\n",
       "         'doctor': 407,\n",
       "         'features': 406,\n",
       "         'unique': 406,\n",
       "         'reasons': 404,\n",
       "         'weird': 403,\n",
       "         'using': 403,\n",
       "         'die': 402,\n",
       "         'deal': 401,\n",
       "         'hot': 401,\n",
       "         'dog': 400,\n",
       "         'showing': 399,\n",
       "         'whether': 399,\n",
       "         'room': 398,\n",
       "         'william': 398,\n",
       "         'previous': 398,\n",
       "         'move': 397,\n",
       "         'leads': 397,\n",
       "         'following': 397,\n",
       "         'forced': 397,\n",
       "         'de': 397,\n",
       "         'japanese': 396,\n",
       "         'actual': 395,\n",
       "         'bill': 395,\n",
       "         'ends': 393,\n",
       "         'third': 393,\n",
       "         'directors': 392,\n",
       "         'plain': 391,\n",
       "         'mark': 390,\n",
       "         'cop': 390,\n",
       "         '9': 390,\n",
       "         'store': 390,\n",
       "         'popular': 388,\n",
       "         'needs': 388,\n",
       "         'society': 386,\n",
       "         'setting': 386,\n",
       "         'general': 385,\n",
       "         'interested': 385,\n",
       "         'yourself': 385,\n",
       "         'mention': 384,\n",
       "         'form': 384,\n",
       "         'particular': 383,\n",
       "         'incredible': 383,\n",
       "         'week': 382,\n",
       "         'points': 382,\n",
       "         'credits': 381,\n",
       "         'shame': 380,\n",
       "         'supporting': 380,\n",
       "         '8': 379,\n",
       "         'clever': 379,\n",
       "         'material': 378,\n",
       "         'giving': 377,\n",
       "         '7': 377,\n",
       "         'buy': 376,\n",
       "         'joe': 376,\n",
       "         'appears': 376,\n",
       "         'adventure': 375,\n",
       "         'stay': 374,\n",
       "         'adaptation': 374,\n",
       "         'talented': 374,\n",
       "         'free': 374,\n",
       "         'laughs': 372,\n",
       "         'hear': 372,\n",
       "         'laughing': 372,\n",
       "         'u': 372,\n",
       "         'beauty': 372,\n",
       "         'dumb': 372,\n",
       "         'writers': 371,\n",
       "         'science': 371,\n",
       "         'spent': 371,\n",
       "         'cute': 370,\n",
       "         'fantasy': 370,\n",
       "         'clear': 370,\n",
       "         'somehow': 369,\n",
       "         'scott': 366,\n",
       "         '15': 365,\n",
       "         'e': 364,\n",
       "         'killing': 364,\n",
       "         'expectations': 363,\n",
       "         'male': 363,\n",
       "         'viewers': 363,\n",
       "         'crew': 362,\n",
       "         'street': 361,\n",
       "         'older': 361,\n",
       "         'total': 361,\n",
       "         'dance': 360,\n",
       "         'fiction': 360,\n",
       "         'mess': 359,\n",
       "         'casting': 358,\n",
       "         'truth': 358,\n",
       "         'italian': 357,\n",
       "         'era': 357,\n",
       "         'sounds': 355,\n",
       "         'check': 355,\n",
       "         'wasted': 355,\n",
       "         'follows': 355,\n",
       "         'wait': 355,\n",
       "         'nor': 354,\n",
       "         'red': 354,\n",
       "         'potential': 354,\n",
       "         'created': 354,\n",
       "         'rate': 353,\n",
       "         'concept': 353,\n",
       "         'forget': 353,\n",
       "         'rich': 353,\n",
       "         'atmosphere': 353,\n",
       "         'means': 353,\n",
       "         '6': 352,\n",
       "         'awesome': 352,\n",
       "         'success': 352,\n",
       "         'german': 351,\n",
       "         'plus': 351,\n",
       "         'missed': 350,\n",
       "         'sexual': 350,\n",
       "         'secret': 350,\n",
       "         'meet': 349,\n",
       "         'filled': 349,\n",
       "         'footage': 349,\n",
       "         'leaves': 349,\n",
       "         'girlfriend': 348,\n",
       "         'powerful': 348,\n",
       "         'intelligent': 348,\n",
       "         'figure': 347,\n",
       "         'perfectly': 347,\n",
       "         'fails': 346,\n",
       "         'unlike': 346,\n",
       "         'portrayed': 346,\n",
       "         'earlier': 344,\n",
       "         'joke': 343,\n",
       "         'fairly': 343,\n",
       "         'ideas': 343,\n",
       "         'stage': 341,\n",
       "         'odd': 341,\n",
       "         'sequences': 340,\n",
       "         'question': 340,\n",
       "         'telling': 340,\n",
       "         'hands': 340,\n",
       "         'christmas': 340,\n",
       "         'bored': 339,\n",
       "         'whatever': 339,\n",
       "         'development': 339,\n",
       "         'quickly': 339,\n",
       "         'result': 338,\n",
       "         'showed': 338,\n",
       "         'baby': 337,\n",
       "         'comedies': 336,\n",
       "         'zombie': 336,\n",
       "         ...})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs # Most frequent words in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_data(train_df, vocab, max_tokens)\n",
    "val_data = prepare_data(val_df, vocab, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's Define our Dataset and Dataloader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            data: list of tuples (raw_text, tokens, token_indices, sentiment)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        # Sorting by token list length (largest first)\n",
    "        self.data.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            i: an integer index\n",
    "        Outputs:\n",
    "            data: A dictionary of {data, label}\n",
    "        \"\"\"\n",
    "        _, _, indices, sentiment = self.data[i]\n",
    "        return {\n",
    "            'data': torch.tensor(indices).long(),\n",
    "            'label': torch.tensor(sentiment).float()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset objects.\n",
    "train_dataset = SentimentDataset(train_data)\n",
    "val_dataset = SentimentDataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the datastet: 40000\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': tensor([10, 13, 41,  4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1, 49, 21,  1,  2,  1, 24,  1,  1, 33,\n",
       "         23, 32,  1,  1, 10,  6,  5,  1,  1,  3,  1, 41,  1,  3,  1, 36, 25, 40,\n",
       "          1,  1,  1, 17,  1,  1,  3,  1, 27,  1,  1, 19,  1,  1, 10, 38,  1,  1,\n",
       "          1,  1,  8,  1,  1,  1, 19,  1]),\n",
       " 'label': tensor(0.)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Length of the datastet: {len(train_dataset)}')\n",
    "print('Sample:')\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a collate function for DataLoader to correctly handle batches.\n",
    "def collate(batch):\n",
    "    data = pad_sequence([item['data'] for item in batch])\n",
    "    lengths = torch.tensor([len(item['data']) for item in batch])\n",
    "    labels = torch.stack([item['label'] for item in batch])\n",
    "    return {\n",
    "        'data': data,\n",
    "        'lengths': lengths,\n",
    "        'label': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([[ 1,  1, 41,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "         [ 1,  1,  1,  ...,  1,  1, 38],\n",
       "         ...,\n",
       "         [49,  1,  4,  ..., 36, 36,  1],\n",
       "         [ 1, 38,  1,  ...,  1,  1,  1],\n",
       "         [ 1, 47,  1,  ...,  3,  1, 14]]),\n",
       " 'lengths': tensor([80, 80, 80, 80, 60, 80, 80, 80, 80, 80, 55, 80, 57, 80, 80, 80]),\n",
       " 'label': tensor([1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.])}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we will use our <code>RNNClassifier</code> that uses the output of last hidden layer of lstm to predict the label.\n",
    "Have a look at the <code>RNNClassfier</code> class in <code>classfier.py</code> to get better understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RNNClassifier uses LSTM and Embedding, check  <code>Embedding</code> and <code>LSTM</code> classes in <code>layers.py</code> file to completely understand the implementation part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import RNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(model, data_loader):\n",
    "    \"\"\"Computes the accuracy of the model\"\"\"\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    device = next(model.parameters())\n",
    "    \n",
    "    for i, x in enumerate(data_loader):\n",
    "        input = x['data']\n",
    "        lengths = x['lengths']\n",
    "        label = x['label']\n",
    "        pred = model(input, lengths)\n",
    "        corrects += ((pred > 0.5) == label).sum().item()\n",
    "        total += label.numel()\n",
    "        \n",
    "        if i > 0  and i % 100 == 0:\n",
    "            print('Step {} / {}'.format(i, len(data_loader)))\n",
    "    \n",
    "    return corrects / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(num_embeddings=len(vocab), embedding_dim=20, hidden_size=32)\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define the training function in accordance with pytorch's training pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/10]: 100%|██████████| 2500/2500 [01:19<00:00, 31.51it/s, loss=0.658]\n",
      "Validation Epoch [1/10]: 100%|██████████| 625/625 [00:05<00:00, 110.67it/s, loss=0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6848, Val Loss: 0.6680, Accuracy: 59.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [2/10]: 100%|██████████| 2500/2500 [01:21<00:00, 30.66it/s, loss=0.565]\n",
      "Validation Epoch [2/10]: 100%|██████████| 625/625 [00:05<00:00, 112.43it/s, loss=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6631, Val Loss: 0.6566, Accuracy: 61.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [3/10]: 100%|██████████| 2500/2500 [01:18<00:00, 31.75it/s, loss=0.679]\n",
      "Validation Epoch [3/10]: 100%|██████████| 625/625 [00:05<00:00, 116.54it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.6507, Val Loss: 0.6526, Accuracy: 61.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [4/10]: 100%|██████████| 2500/2500 [01:18<00:00, 31.74it/s, loss=0.772]\n",
      "Validation Epoch [4/10]: 100%|██████████| 625/625 [00:06<00:00, 102.00it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.6426, Val Loss: 0.6451, Accuracy: 62.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [5/10]: 100%|██████████| 2500/2500 [01:20<00:00, 30.92it/s, loss=0.627]\n",
      "Validation Epoch [5/10]: 100%|██████████| 625/625 [00:05<00:00, 114.52it/s, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.6343, Val Loss: 0.6430, Accuracy: 62.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [6/10]: 100%|██████████| 2500/2500 [01:19<00:00, 31.37it/s, loss=0.561]\n",
      "Validation Epoch [6/10]: 100%|██████████| 625/625 [00:05<00:00, 111.63it/s, loss=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.6280, Val Loss: 0.6384, Accuracy: 62.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [7/10]: 100%|██████████| 2500/2500 [01:17<00:00, 32.19it/s, loss=0.592]\n",
      "Validation Epoch [7/10]: 100%|██████████| 625/625 [00:05<00:00, 116.08it/s, loss=0.725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.6218, Val Loss: 0.6366, Accuracy: 63.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [8/10]: 100%|██████████| 2500/2500 [01:17<00:00, 32.35it/s, loss=0.53] \n",
      "Validation Epoch [8/10]: 100%|██████████| 625/625 [00:05<00:00, 123.77it/s, loss=0.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.6156, Val Loss: 0.6378, Accuracy: 63.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [9/10]: 100%|██████████| 2500/2500 [01:14<00:00, 33.41it/s, loss=0.784]\n",
      "Validation Epoch [9/10]: 100%|██████████| 625/625 [00:05<00:00, 124.60it/s, loss=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.6099, Val Loss: 0.6369, Accuracy: 63.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [10/10]: 100%|██████████| 2500/2500 [01:19<00:00, 31.58it/s, loss=0.521]\n",
      "Validation Epoch [10/10]: 100%|██████████| 625/625 [00:05<00:00, 115.27it/s, loss=0.713]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.6040, Val Loss: 0.6345, Accuracy: 63.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def initialize_training(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=10,\n",
    "    lr=0.001,\n",
    "    criterion=None,\n",
    "    optimizer_class=torch.optim.Adam\n",
    "):\n",
    "    \"\"\"\n",
    "    Initializes the training process and runs the training/validation loops.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to be trained.\n",
    "        train_loader: DataLoader for training data (returns dict with keys ['data', 'label', 'lengths']).\n",
    "        val_loader: DataLoader for validation data (same structure as train_loader).\n",
    "        epochs: Number of epochs to train for.\n",
    "        lr: Learning rate for the optimizer.\n",
    "        criterion: Loss function to use (default: BCELoss).\n",
    "        optimizer_class: Optimizer class to use (default: Adam).\n",
    "    \"\"\"\n",
    "    if criterion is None:\n",
    "        criterion = nn.BCELoss()  # Default to binary cross-entropy loss\n",
    "\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_loop = tqdm(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=epochs * len(train_loader) / 5, gamma=0.7)\n",
    "\n",
    "        \n",
    "        for batch in train_loop:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Extract data, labels, and lengths from batch\n",
    "            sequences = batch['data']  # Input sequences\n",
    "            labels = batch['label']    # Ground truth labels\n",
    "            lengths = batch['lengths'] # Actual lengths of sequences\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sequences, lengths)  # Transpose sequences to (seq_len, batch_size)\n",
    "            \n",
    "            # Calculate loss and perform backpropagation\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "        scheduler.step()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loop = tqdm(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loop:\n",
    "                sequences = batch['data']  # Input sequences\n",
    "                labels = batch['label']    # Ground truth labels\n",
    "                lengths = batch['lengths'] # Actual lengths of sequences\n",
    "\n",
    "                outputs = model(sequences, lengths)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                predictions = (outputs > 0.5).float()  # Threshold at 0.5\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                val_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = correct / total * 100\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "initialize_training(model=model, train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we cna see model achieves around 64% accuracy which is a little bit better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sentiment_analysis_with_bert.ipynb` we will increase the accuracy using pretrained transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
