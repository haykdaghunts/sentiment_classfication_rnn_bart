{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using Bert Transformer"
      ],
      "metadata": {
        "id": "-8n6_WsMaY5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook demonstrates the fine-tunning of a Pretrained Bart Transormer to predict the sentiment of the IMBD movie ratings dataset"
      ],
      "metadata": {
        "id": "G2fNfockbKyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Ham9fkreZiHI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '../IMDB Dataset.csv' # path to the CSV file"
      ],
      "metadata": {
        "id": "W5dnDbtVlgXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "KGQfjPltmr4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path)\n",
        "texts = df['review'].tolist()\n",
        "labels = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).tolist()\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jGjSermYe61h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "d7BZDIr_LgzD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "NwK5eNpJo_1q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 64  # Maximum sequence length\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
        "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n"
      ],
      "metadata": {
        "id": "87_7srUWfjsj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhkfRmyOrAla",
        "outputId": "dfc5ae6e-81a2-45c3-9424-bba2c44d8c3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  2008,  1005,  1055,  2054,  1045,  2921,  4851,  2870,  2076,\n",
              "          1996,  2116,  9590,  1010,  7491,  3503,  1010, 25082,  1998,  2236,\n",
              "         26865,  2008,  2566,  4168,  3686,  1996,  6391,  2781,  1012,  1996,\n",
              "         18539,  2036,  3233,  2039,  2043,  2017,  2228,  1997,  1996,  2028,\n",
              "          1011,  8789,  3494,  1010,  2040,  2031,  2061,  2210,  5995,  2008,\n",
              "          2009,  2003,  8990,  5263,  2000,  2729,  2054,  6433,  2000,  2068,\n",
              "          1012,  2027,  2024,   102]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'label': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "JLlG5a5Omn4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "6-Irz9uSmP1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training we will fine-tune the bart model which is an encoder-only transformer meant for solving tasks like text classifcaition.\n",
        "We will take the final embedding representation of the `[CLS]` token and fed it to linear layer for classification"
      ],
      "metadata": {
        "id": "qfZ6OelFnkKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', num_classes=1):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output  # Use the [CLS] token's embedding\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return torch.sigmoid(logits)  # Apply sigmoid for binary classification"
      ],
      "metadata": {
        "id": "W8eHoCDBmdaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our model is quite large we will use colab's gpu to train the model"
      ],
      "metadata": {
        "id": "uS_L2OIUomRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "BTjQ92PbfnaW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "UrK7OKA2Uz6U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    # Create a tqdm progress bar for the training loop\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{EPOCHS}', leave=False)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Update the progress bar with the current loss\n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        # Flush print statements in Colab\n",
        "        #sys.stdout.flush()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}, Loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gngRzk5VUDn",
        "outputId": "062391ff-d809-4887-f25d-b4758b9980d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.4413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3, Loss: 0.3187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3, Loss: 0.2466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        preds = (outputs.squeeze() > 0.5).long()\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHFkyexjWtii",
        "outputId": "58178b61-ead3-43c5-d98d-17e6647911cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see our transformerbased model performs significantly better than RNN by achieving an accuracy of about 84%"
      ],
      "metadata": {
        "id": "qY1CQjwapEIm"
      }
    }
  ]
}